{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02で前処理をしたデータの読み込みとモデルの学習を行うためのnotebookです。  \n",
    "ここで作成したモデルは **src/models/** フォルダに格納して推論の際に使うようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "import optuna.integration.lightgbm as lgbo\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borutaでlightgbmを使うためのクラス\n",
    "# https://qiita.com/studio_haneya/items/1366738e4a7b273fd1fd\n",
    "\n",
    "class BorutaPyForLGB(BorutaPy):\n",
    "    def __init__(self, estimator, n_estimators=1000, perc=100, alpha=0.05,\n",
    "                 two_step=True, max_iter=100, random_state=None, verbose=0):\n",
    "        super().__init__(estimator, n_estimators, perc, alpha,\n",
    "                         two_step, max_iter, random_state, verbose)\n",
    "        if random_state is None:\n",
    "            self.random_state_input = np.random.randint(0, 2**64-1)\n",
    "        elif isinstance(random_state, int):\n",
    "            self.random_state_input = random_state\n",
    "        else:\n",
    "            raise TypeError('random_state must be int or None')\n",
    "\n",
    "    def _get_tree_num(self, n_feat):\n",
    "        depth = self.estimator.get_params()['max_depth']\n",
    "        if (depth == None) or (depth <= 0):\n",
    "            depth = 10\n",
    "        f_repr = 100\n",
    "        multi = ((n_feat * 2) / (np.sqrt(n_feat * 2) * depth))\n",
    "        n_estimators = int(multi * f_repr)\n",
    "        return n_estimators\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        # check input params\n",
    "        # self._check_params(X, y)\n",
    "        self.random_state = check_random_state(self.random_state)\n",
    "        # setup variables for Boruta\n",
    "        n_sample, n_feat = X.shape\n",
    "        _iter = 1\n",
    "        # holds the decision about each feature:\n",
    "        # 0  - default state = tentative in original code\n",
    "        # 1  - accepted in original code\n",
    "        # -1 - rejected in original code\n",
    "        dec_reg = np.zeros(n_feat, dtype=np.int64)\n",
    "        # counts how many times a given feature was more important than\n",
    "        # the best of the shadow features\n",
    "        hit_reg = np.zeros(n_feat, dtype=np.int64)\n",
    "        # these record the history of the iterations\n",
    "        imp_history = np.zeros(n_feat, dtype=np.float64)\n",
    "        sha_max_history = []\n",
    "\n",
    "        # set n_estimators\n",
    "        if self.n_estimators != 'auto':\n",
    "            self.estimator.set_params(n_estimators=self.n_estimators)\n",
    "\n",
    "        # main feature selection loop\n",
    "        while np.any(dec_reg == 0) and _iter < self.max_iter:\n",
    "            # find optimal number of trees and depth\n",
    "            if self.n_estimators == 'auto':\n",
    "                # number of features that aren't rejected\n",
    "                not_rejected = np.where(dec_reg >= 0)[0].shape[0]\n",
    "                n_tree = self._get_tree_num(not_rejected)\n",
    "                self.estimator.set_params(n_estimators=n_tree)\n",
    "\n",
    "            # make sure we start with a new tree in each iteration\n",
    "            self.estimator.set_params(random_state=self.random_state_input)\n",
    "\n",
    "            # add shadow attributes, shuffle them and train estimator, get imps\n",
    "            cur_imp = self._add_shadows_get_imps(X, y, dec_reg)\n",
    "\n",
    "            # get the threshold of shadow importances we will use for rejection\n",
    "            imp_sha_max = np.percentile(cur_imp[1], self.perc)\n",
    "\n",
    "            # record importance history\n",
    "            sha_max_history.append(imp_sha_max)\n",
    "            imp_history = np.vstack((imp_history, cur_imp[0]))\n",
    "\n",
    "            # register which feature is more imp than the max of shadows\n",
    "            hit_reg = self._assign_hits(hit_reg, cur_imp, imp_sha_max)\n",
    "\n",
    "            # based on hit_reg we check if a feature is doing better than\n",
    "            # expected by chance\n",
    "            dec_reg = self._do_tests(dec_reg, hit_reg, _iter)\n",
    "\n",
    "            # print out confirmed features\n",
    "            if self.verbose > 0 and _iter < self.max_iter:\n",
    "                self._print_results(dec_reg, _iter, 0)\n",
    "            if _iter < self.max_iter:\n",
    "                _iter += 1\n",
    "\n",
    "        # we automatically apply R package's rough fix for tentative ones\n",
    "        confirmed = np.where(dec_reg == 1)[0]\n",
    "        tentative = np.where(dec_reg == 0)[0]\n",
    "        # ignore the first row of zeros\n",
    "        tentative_median = np.median(imp_history[1:, tentative], axis=0)\n",
    "        # which tentative to keep\n",
    "        tentative_confirmed = np.where(tentative_median\n",
    "                                       > np.median(sha_max_history))[0]\n",
    "        tentative = tentative[tentative_confirmed]\n",
    "\n",
    "        # basic result variables\n",
    "        self.n_features_ = confirmed.shape[0]\n",
    "        self.support_ = np.zeros(n_feat, dtype=np.bool_)\n",
    "        self.support_[confirmed] = 1\n",
    "        self.support_weak_ = np.zeros(n_feat, dtype=np.bool_)\n",
    "        self.support_weak_[tentative] = 1\n",
    "\n",
    "        # ranking, confirmed variables are rank 1\n",
    "        self.ranking_ = np.ones(n_feat, dtype=np.int64)\n",
    "        # tentative variables are rank 2\n",
    "        self.ranking_[tentative] = 2\n",
    "        # selected = confirmed and tentative\n",
    "        selected = np.hstack((confirmed, tentative))\n",
    "        # all rejected features are sorted by importance history\n",
    "        not_selected = np.setdiff1d(np.arange(n_feat), selected)\n",
    "        # large importance values should rank higher = lower ranks -> *(-1)\n",
    "        imp_history_rejected = imp_history[1:, not_selected] * -1\n",
    "\n",
    "        # update rank for not_selected features\n",
    "        if not_selected.shape[0] > 0:\n",
    "                # calculate ranks in each iteration, then median of ranks across feats\n",
    "                iter_ranks = self._nanrankdata(imp_history_rejected, axis=1)\n",
    "                rank_medians = np.nanmedian(iter_ranks, axis=0)\n",
    "                ranks = self._nanrankdata(rank_medians, axis=0)\n",
    "\n",
    "                # set smallest rank to 3 if there are tentative feats\n",
    "                if tentative.shape[0] > 0:\n",
    "                    ranks = ranks - np.min(ranks) + 3\n",
    "                else:\n",
    "                    # and 2 otherwise\n",
    "                    ranks = ranks - np.min(ranks) + 2\n",
    "                self.ranking_[not_selected] = ranks\n",
    "        else:\n",
    "            # all are selected, thus we set feature supports to True\n",
    "            self.support_ = np.ones(n_feat, dtype=np.bool_)\n",
    "\n",
    "        # notify user\n",
    "        if self.verbose > 0:\n",
    "            self._print_results(dec_reg, _iter, 1)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('../data/processed/processed20240621_train.csv')\n",
    "# 目的変数と説明変数の作成\n",
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "errvalue = target.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量選定とハイパラ調整（実行しなくてもOK）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字列のカラムがあると特徴量選択とハイパラ調整でエラーが出るので、最初の決済月とカードIDを消す\n",
    "train_ = train.drop('first_active_month', axis=1)\n",
    "del train_['card_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65747\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 327\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "SCORE with ALL Features: 13.69\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.376206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.315061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.301045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.323366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.295465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.354127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.365458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.405545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.284442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.295983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.316882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.319699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131494\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 654\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31880\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31880\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31880\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31880\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26988\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26988\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26988\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26988\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25838\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25838\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25838\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23288\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23288\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23288\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23288\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22768\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 98\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22768\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 98\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22768\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 98\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21764\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21764\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21764\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20728\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20728\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20728\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20728\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20728\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19748\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19238\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19238\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19238\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18218\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17708\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "Index(['elapsed_time', 'hist_category_1_sum', 'hist_installments_sum',\n",
      "       'hist_purchase_date_ptp', 'hist_purchase_date_min',\n",
      "       'hist_month_diff_mean', 'hist_merchant_avg_purchases_lag3_sum',\n",
      "       'hist_merchant_active_months_lag12_sum', 'auth_category_1_sum',\n",
      "       'auth_category_1_mean', 'auth_purchase_amount_sum',\n",
      "       'auth_installments_sum', 'auth_purchase_month_std',\n",
      "       'auth_purchase_date_ptp', 'auth_purchase_date_min',\n",
      "       'auth_purchase_date_max', 'auth_month_lag_mean', 'auth_month_diff_mean',\n",
      "       'auth_merchant_group_id_nunique',\n",
      "       'auth_merchant_avg_purchases_lag3_min', 'new_category_1_sum',\n",
      "       'new_category_1_mean', 'new_purchase_amount_sum',\n",
      "       'new_purchase_amount_mean', 'new_purchase_amount_max',\n",
      "       'new_purchase_amount_std', 'new_purchase_month_mean',\n",
      "       'new_purchase_date_ptp', 'new_purchase_date_min',\n",
      "       'new_purchase_date_max', 'new_month_lag_mean',\n",
      "       'new_merchant_avg_purchases_lag6_sum', 'month_lag_std',\n",
      "       'purchase_amount_count_mean', 'purchase_amount_mean_mean',\n",
      "       'purchase_amount_max_mean', 'authorized_flag_mean'],\n",
      "      dtype='object')\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8642\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.392633\n",
      "SCORE with selected Features: 13.69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_, target, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# 特徴量選択なしの場合\n",
    "model = lgb.LGBMRegressor(objective='regression',\n",
    "                           metric='rmse',\n",
    "                            num_leaves = 23,\n",
    "                            learning_rate=0.1,\n",
    "                            n_estimators=100,)\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "y_test_pred = model.predict(X_test.values)\n",
    "y_test_pred = np.where(y_test_pred < -20, errvalue, y_test_pred)\n",
    "\n",
    "print('SCORE with ALL Features: %1.2f\\n' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Borutaで特徴量選択 (一部書き換えたBorutaPyを使います)\n",
    "model_f = lgb.LGBMRegressor(objective='regression',\n",
    "                           metric='rmse',\n",
    "                            num_leaves = 23,\n",
    "                            learning_rate=0.1,\n",
    "                            n_estimators=100,)\n",
    "feat_selector = BorutaPyForLGB(model_f, n_estimators='auto', perc=80, max_iter=500, two_step=False,verbose=0, random_state=42)\n",
    "feat_selector.fit(X_train.values, y_train.values)\n",
    "print(train_.columns[feat_selector.support_])\n",
    "\n",
    "# 選択したFeatureを取り出し\n",
    "X_train_selected = X_train.iloc[:,feat_selector.support_]\n",
    "X_test_selected = X_test.iloc[:,feat_selector.support_]\n",
    "\n",
    "# 選択したFeatureで学習\n",
    "model_f = lgb.LGBMRegressor(objective='regression',\n",
    "                           metric='rmse',\n",
    "                            num_leaves = 23,\n",
    "                            learning_rate=0.1,\n",
    "                            n_estimators=100,)\n",
    "model_f.fit(X_train_selected.values, y_train.values)\n",
    "\n",
    "y_test_pred_f = model_f.predict(X_test_selected.values)\n",
    "y_test_pred_f = np.where(y_test_pred < -20, errvalue, y_test_pred)\n",
    "print('SCORE with selected Features: %1.2f\\n' % mean_squared_error(y_test, y_test_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 10:55:30,023] A new study created in memory with name: no-name-ac9ec5f9-38b4-4b44-99b0-73008edfff89\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67759 + 0.0282594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.676041:  14%|#4        | 1/7 [00:04<00:27,  4.64s/it][I 2024-06-21 10:55:34,834] Trial 0 finished with value: 3.676041128130275 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 3.676041128130275.\n",
      "feature_fraction, val_score: 3.676041:  14%|#4        | 1/7 [00:04<00:27,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tcv_agg's valid rmse: 3.67604 + 0.027587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67307 + 0.0285054\n",
      "[200]\tcv_agg's valid rmse: 3.67776 + 0.027632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917:  29%|##8       | 2/7 [00:12<00:31,  6.34s/it][I 2024-06-21 10:55:42,297] Trial 1 finished with value: 3.6729167251133807 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917:  29%|##8       | 2/7 [00:12<00:31,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tcv_agg's valid rmse: 3.67292 + 0.0281552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67429 + 0.0263921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917:  43%|####2     | 3/7 [00:17<00:23,  5.84s/it][I 2024-06-21 10:55:47,550] Trial 2 finished with value: 3.6741766513623135 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917:  43%|####2     | 3/7 [00:17<00:23,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's valid rmse: 3.67812 + 0.0251781\n",
      "Early stopping, best iteration is:\n",
      "[101]\tcv_agg's valid rmse: 3.67418 + 0.0264561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67469 + 0.0278196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917:  57%|#####7    | 4/7 [00:21<00:15,  5.09s/it][I 2024-06-21 10:55:51,490] Trial 3 finished with value: 3.6738325551597293 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917:  57%|#####7    | 4/7 [00:21<00:15,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid rmse: 3.67383 + 0.0277531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67766 + 0.0276663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917:  71%|#######1  | 5/7 [00:24<00:09,  4.55s/it][I 2024-06-21 10:55:55,086] Trial 4 finished with value: 3.6773987532925916 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917:  71%|#######1  | 5/7 [00:24<00:09,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tcv_agg's valid rmse: 3.6774 + 0.0284297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67595 + 0.0269505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917:  86%|########5 | 6/7 [00:28<00:04,  4.27s/it][I 2024-06-21 10:55:58,808] Trial 5 finished with value: 3.6747824985106874 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917:  86%|########5 | 6/7 [00:28<00:04,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tcv_agg's valid rmse: 3.67478 + 0.0256932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67381 + 0.0293625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 3.672917: 100%|##########| 7/7 [00:33<00:00,  4.30s/it][I 2024-06-21 10:56:03,186] Trial 6 finished with value: 3.6734198748038964 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 3.6729167251133807.\n",
      "feature_fraction, val_score: 3.672917: 100%|##########| 7/7 [00:33<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's valid rmse: 3.67875 + 0.0284059\n",
      "Early stopping, best iteration is:\n",
      "[102]\tcv_agg's valid rmse: 3.67342 + 0.0292764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.672917:   0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.70306 + 0.0264264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.672917:   5%|5         | 1/20 [00:06<01:57,  6.21s/it][I 2024-06-21 10:56:09,397] Trial 7 finished with value: 3.689615213443241 and parameters: {'num_leaves': 141}. Best is trial 7 with value: 3.689615213443241.\n",
      "num_leaves, val_score: 3.672917:   5%|5         | 1/20 [00:06<01:57,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tcv_agg's valid rmse: 3.68962 + 0.0255089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.70598 + 0.0271432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.672917:  10%|#         | 2/20 [00:13<02:01,  6.75s/it][I 2024-06-21 10:56:16,528] Trial 8 finished with value: 3.6893748744663526 and parameters: {'num_leaves': 184}. Best is trial 8 with value: 3.6893748744663526.\n",
      "num_leaves, val_score: 3.672917:  10%|#         | 2/20 [00:13<02:01,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tcv_agg's valid rmse: 3.68937 + 0.0261011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.70692 + 0.0258768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.672917:  15%|#5        | 3/20 [00:19<01:50,  6.49s/it][I 2024-06-21 10:56:22,716] Trial 9 finished with value: 3.6926185342232336 and parameters: {'num_leaves': 155}. Best is trial 8 with value: 3.6893748744663526.\n",
      "num_leaves, val_score: 3.672917:  15%|#5        | 3/20 [00:19<01:50,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid rmse: 3.69262 + 0.0274564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67494 + 0.0272727\n",
      "[200]\tcv_agg's valid rmse: 3.66911 + 0.0259633\n",
      "[300]\tcv_agg's valid rmse: 3.66878 + 0.025747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  20%|##        | 4/20 [00:24<01:31,  5.72s/it][I 2024-06-21 10:56:27,252] Trial 10 finished with value: 3.6680110856776738 and parameters: {'num_leaves': 7}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  20%|##        | 4/20 [00:24<01:31,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[242]\tcv_agg's valid rmse: 3.66801 + 0.0251685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67494 + 0.0272727\n",
      "[200]\tcv_agg's valid rmse: 3.66911 + 0.0259633\n",
      "[300]\tcv_agg's valid rmse: 3.66878 + 0.025747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  25%|##5       | 5/20 [00:28<01:19,  5.30s/it][I 2024-06-21 10:56:31,806] Trial 11 finished with value: 3.6680110856776738 and parameters: {'num_leaves': 7}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  25%|##5       | 5/20 [00:28<01:19,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[242]\tcv_agg's valid rmse: 3.66801 + 0.0251685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67494 + 0.0272727\n",
      "[200]\tcv_agg's valid rmse: 3.66911 + 0.0259633\n",
      "[300]\tcv_agg's valid rmse: 3.66878 + 0.025747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  30%|###       | 6/20 [00:33<01:10,  5.06s/it][I 2024-06-21 10:56:36,406] Trial 12 finished with value: 3.6680110856776738 and parameters: {'num_leaves': 7}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  30%|###       | 6/20 [00:33<01:10,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[242]\tcv_agg's valid rmse: 3.66801 + 0.0251685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67494 + 0.0272727\n",
      "[200]\tcv_agg's valid rmse: 3.66911 + 0.0259633\n",
      "[300]\tcv_agg's valid rmse: 3.66878 + 0.025747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  35%|###5      | 7/20 [00:37<01:04,  4.97s/it][I 2024-06-21 10:56:41,173] Trial 13 finished with value: 3.6680110856776738 and parameters: {'num_leaves': 7}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  35%|###5      | 7/20 [00:37<01:04,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[242]\tcv_agg's valid rmse: 3.66801 + 0.0251685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.68602 + 0.0297184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  40%|####      | 8/20 [00:42<00:57,  4.81s/it][I 2024-06-21 10:56:45,643] Trial 14 finished with value: 3.6816803964660023 and parameters: {'num_leaves': 68}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  40%|####      | 8/20 [00:42<00:57,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tcv_agg's valid rmse: 3.68168 + 0.0275609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.71113 + 0.0256525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  45%|####5     | 9/20 [00:50<01:05,  5.95s/it][I 2024-06-21 10:56:54,092] Trial 15 finished with value: 3.690982048290514 and parameters: {'num_leaves': 243}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  45%|####5     | 9/20 [00:50<01:05,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[23]\tcv_agg's valid rmse: 3.69098 + 0.025862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.68332 + 0.0250719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  50%|#####     | 10/20 [00:56<00:58,  5.82s/it][I 2024-06-21 10:56:59,633] Trial 16 finished with value: 3.6779836136971986 and parameters: {'num_leaves': 70}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  50%|#####     | 10/20 [00:56<00:58,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tcv_agg's valid rmse: 3.67798 + 0.0252623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6857 + 0.0262518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  55%|#####5    | 11/20 [01:02<00:54,  6.02s/it][I 2024-06-21 10:57:06,099] Trial 17 finished with value: 3.6805080476005285 and parameters: {'num_leaves': 69}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  55%|#####5    | 11/20 [01:02<00:54,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tcv_agg's valid rmse: 3.68051 + 0.0256906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67829 + 0.0278896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  60%|######    | 12/20 [01:07<00:45,  5.66s/it][I 2024-06-21 10:57:10,924] Trial 18 finished with value: 3.677244594161086 and parameters: {'num_leaves': 39}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  60%|######    | 12/20 [01:07<00:45,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tcv_agg's valid rmse: 3.67724 + 0.0282816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.69357 + 0.0268188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  65%|######5   | 13/20 [01:13<00:40,  5.79s/it][I 2024-06-21 10:57:17,029] Trial 19 finished with value: 3.6852562003812266 and parameters: {'num_leaves': 98}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  65%|######5   | 13/20 [01:13<00:40,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tcv_agg's valid rmse: 3.68526 + 0.0257829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.76196 + 0.0327399\n",
      "[200]\tcv_agg's valid rmse: 3.74918 + 0.032008\n",
      "[300]\tcv_agg's valid rmse: 3.74379 + 0.0317776\n",
      "[400]\tcv_agg's valid rmse: 3.74068 + 0.0316491\n",
      "[500]\tcv_agg's valid rmse: 3.73847 + 0.0314987\n",
      "[600]\tcv_agg's valid rmse: 3.73687 + 0.0312989\n",
      "[700]\tcv_agg's valid rmse: 3.73553 + 0.0312362\n",
      "[800]\tcv_agg's valid rmse: 3.73442 + 0.0311224\n",
      "[900]\tcv_agg's valid rmse: 3.73351 + 0.0309807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  70%|#######   | 14/20 [01:23<00:41,  6.86s/it][I 2024-06-21 10:57:26,350] Trial 20 finished with value: 3.7327411702248035 and parameters: {'num_leaves': 2}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  70%|#######   | 14/20 [01:23<00:41,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tcv_agg's valid rmse: 3.73275 + 0.030841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tcv_agg's valid rmse: 3.73274 + 0.0308534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6725 + 0.0264042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  75%|#######5  | 15/20 [01:27<00:30,  6.14s/it][I 2024-06-21 10:57:30,816] Trial 21 finished with value: 3.6724144877970724 and parameters: {'num_leaves': 29}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  75%|#######5  | 15/20 [01:27<00:30,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tcv_agg's valid rmse: 3.67241 + 0.0262978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6755 + 0.0302976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  80%|########  | 16/20 [01:31<00:22,  5.57s/it][I 2024-06-21 10:57:35,076] Trial 22 finished with value: 3.6749147420611594 and parameters: {'num_leaves': 37}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  80%|########  | 16/20 [01:31<00:22,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid rmse: 3.67491 + 0.0309449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67932 + 0.0269659\n",
      "[200]\tcv_agg's valid rmse: 3.67165 + 0.027008\n",
      "[300]\tcv_agg's valid rmse: 3.67094 + 0.0269871\n",
      "[400]\tcv_agg's valid rmse: 3.67117 + 0.0262584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  85%|########5 | 17/20 [01:38<00:17,  5.95s/it][I 2024-06-21 10:57:41,894] Trial 23 finished with value: 3.670715646083388 and parameters: {'num_leaves': 6}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  85%|########5 | 17/20 [01:38<00:17,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tcv_agg's valid rmse: 3.67162 + 0.0266581\n",
      "Early stopping, best iteration is:\n",
      "[408]\tcv_agg's valid rmse: 3.67072 + 0.0262025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67934 + 0.0263334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  90%|######### | 18/20 [01:43<00:11,  5.53s/it][I 2024-06-21 10:57:46,440] Trial 24 finished with value: 3.6775934397069605 and parameters: {'num_leaves': 43}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  90%|######### | 18/20 [01:43<00:11,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tcv_agg's valid rmse: 3.67759 + 0.0276055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.69168 + 0.0244798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011:  95%|#########5| 19/20 [01:49<00:05,  5.80s/it][I 2024-06-21 10:57:52,889] Trial 25 finished with value: 3.6841676424179584 and parameters: {'num_leaves': 114}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011:  95%|#########5| 19/20 [01:49<00:05,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tcv_agg's valid rmse: 3.68417 + 0.0225045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6718 + 0.0280718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 3.668011: 100%|##########| 20/20 [01:54<00:00,  5.46s/it][I 2024-06-21 10:57:57,537] Trial 26 finished with value: 3.670800220370514 and parameters: {'num_leaves': 27}. Best is trial 10 with value: 3.6680110856776738.\n",
      "num_leaves, val_score: 3.668011: 100%|##########| 20/20 [01:54<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tcv_agg's valid rmse: 3.67634 + 0.0269037\n",
      "Early stopping, best iteration is:\n",
      "[111]\tcv_agg's valid rmse: 3.6708 + 0.0282929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 3.668011:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67882 + 0.026917\n",
      "[200]\tcv_agg's valid rmse: 3.67505 + 0.0258702\n",
      "[300]\tcv_agg's valid rmse: 3.67546 + 0.0263894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  10%|#         | 1/10 [00:04<00:37,  4.20s/it][I 2024-06-21 10:58:01,750] Trial 27 finished with value: 3.674569751757639 and parameters: {'bagging_fraction': 0.47499601580445705, 'bagging_freq': 7}. Best is trial 27 with value: 3.674569751757639.\n",
      "bagging, val_score: 3.668011:  10%|#         | 1/10 [00:04<00:37,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[221]\tcv_agg's valid rmse: 3.67457 + 0.0272184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67579 + 0.0267982\n",
      "[200]\tcv_agg's valid rmse: 3.66862 + 0.0265989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  10%|#         | 1/10 [00:09<00:37,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tcv_agg's valid rmse: 3.66894 + 0.0260425\n",
      "Early stopping, best iteration is:\n",
      "[213]\tcv_agg's valid rmse: 3.66803 + 0.0266421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  20%|##        | 2/10 [00:09<00:39,  4.98s/it][I 2024-06-21 10:58:07,270] Trial 28 finished with value: 3.6680344566083756 and parameters: {'bagging_fraction': 0.9716669565170226, 'bagging_freq': 1}. Best is trial 28 with value: 3.6680344566083756.\n",
      "bagging, val_score: 3.668011:  20%|##        | 2/10 [00:09<00:39,  4.98s/it]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67705 + 0.0283326\n",
      "[200]\tcv_agg's valid rmse: 3.67112 + 0.0276499\n",
      "[300]\tcv_agg's valid rmse: 3.67099 + 0.0264597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  30%|###       | 3/10 [00:16<00:41,  5.91s/it][I 2024-06-21 10:58:14,281] Trial 29 finished with value: 3.6708904321436564 and parameters: {'bagging_fraction': 0.8085659407929188, 'bagging_freq': 4}. Best is trial 28 with value: 3.6680344566083756.\n",
      "bagging, val_score: 3.668011:  30%|###       | 3/10 [00:16<00:41,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[299]\tcv_agg's valid rmse: 3.67089 + 0.0263297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.68268 + 0.0251366\n",
      "[200]\tcv_agg's valid rmse: 3.67915 + 0.0238097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  40%|####      | 4/10 [00:20<00:30,  5.17s/it][I 2024-06-21 10:58:18,313] Trial 30 finished with value: 3.678230759577455 and parameters: {'bagging_fraction': 0.4356241640466338, 'bagging_freq': 7}. Best is trial 28 with value: 3.6680344566083756.\n",
      "bagging, val_score: 3.668011:  40%|####      | 4/10 [00:20<00:30,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tcv_agg's valid rmse: 3.68022 + 0.0228637\n",
      "Early stopping, best iteration is:\n",
      "[214]\tcv_agg's valid rmse: 3.67823 + 0.0235955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67766 + 0.0271146\n",
      "[200]\tcv_agg's valid rmse: 3.67194 + 0.0267218\n",
      "[300]\tcv_agg's valid rmse: 3.6719 + 0.0260508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  50%|#####     | 5/10 [00:26<00:27,  5.47s/it][I 2024-06-21 10:58:24,330] Trial 31 finished with value: 3.6708053474940265 and parameters: {'bagging_fraction': 0.6589607486797602, 'bagging_freq': 1}. Best is trial 28 with value: 3.6680344566083756.\n",
      "bagging, val_score: 3.668011:  50%|#####     | 5/10 [00:26<00:27,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[282]\tcv_agg's valid rmse: 3.67081 + 0.0266237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67645 + 0.0258162\n",
      "[200]\tcv_agg's valid rmse: 3.67193 + 0.0265665\n",
      "[300]\tcv_agg's valid rmse: 3.67251 + 0.0266371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.668011:  60%|######    | 6/10 [00:32<00:21,  5.43s/it][I 2024-06-21 10:58:29,666] Trial 32 finished with value: 3.6714934181409022 and parameters: {'bagging_fraction': 0.668965055671845, 'bagging_freq': 4}. Best is trial 28 with value: 3.6680344566083756.\n",
      "bagging, val_score: 3.668011:  60%|######    | 6/10 [00:32<00:21,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[228]\tcv_agg's valid rmse: 3.67149 + 0.0266046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67383 + 0.0278768\n",
      "[200]\tcv_agg's valid rmse: 3.6681 + 0.0264093\n",
      "[300]\tcv_agg's valid rmse: 3.6677 + 0.025748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.667047:  70%|#######   | 7/10 [00:39<00:18,  6.07s/it][I 2024-06-21 10:58:37,064] Trial 33 finished with value: 3.6670469345466197 and parameters: {'bagging_fraction': 0.999528917168157, 'bagging_freq': 5}. Best is trial 33 with value: 3.6670469345466197.\n",
      "bagging, val_score: 3.667047:  70%|#######   | 7/10 [00:39<00:18,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[273]\tcv_agg's valid rmse: 3.66705 + 0.0262964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67391 + 0.0283856\n",
      "[200]\tcv_agg's valid rmse: 3.66955 + 0.0277145\n",
      "[300]\tcv_agg's valid rmse: 3.66871 + 0.0278379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.667047:  80%|########  | 8/10 [00:46<00:12,  6.31s/it][I 2024-06-21 10:58:43,877] Trial 34 finished with value: 3.667969048737654 and parameters: {'bagging_fraction': 0.9206810555728682, 'bagging_freq': 5}. Best is trial 33 with value: 3.6670469345466197.\n",
      "bagging, val_score: 3.667047:  80%|########  | 8/10 [00:46<00:12,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[247]\tcv_agg's valid rmse: 3.66797 + 0.0269846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67571 + 0.0274188\n",
      "[200]\tcv_agg's valid rmse: 3.66967 + 0.0260743\n",
      "[300]\tcv_agg's valid rmse: 3.66906 + 0.0243648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.667047:  90%|######### | 9/10 [00:53<00:06,  6.52s/it][I 2024-06-21 10:58:50,880] Trial 35 finished with value: 3.6689199412692384 and parameters: {'bagging_fraction': 0.9872771352238836, 'bagging_freq': 5}. Best is trial 33 with value: 3.6670469345466197.\n",
      "bagging, val_score: 3.667047:  90%|######### | 9/10 [00:53<00:06,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[244]\tcv_agg's valid rmse: 3.66892 + 0.0253817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67665 + 0.028153\n",
      "[200]\tcv_agg's valid rmse: 3.67219 + 0.0268899\n",
      "[300]\tcv_agg's valid rmse: 3.67108 + 0.0272679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 3.667047: 100%|##########| 10/10 [01:00<00:00,  6.84s/it][I 2024-06-21 10:58:58,435] Trial 36 finished with value: 3.670729041845969 and parameters: {'bagging_fraction': 0.8460326340898549, 'bagging_freq': 5}. Best is trial 33 with value: 3.6670469345466197.\n",
      "bagging, val_score: 3.667047: 100%|##########| 10/10 [01:00<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tcv_agg's valid rmse: 3.67221 + 0.0276669\n",
      "Early stopping, best iteration is:\n",
      "[304]\tcv_agg's valid rmse: 3.67073 + 0.0270484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67496 + 0.0278619\n",
      "[200]\tcv_agg's valid rmse: 3.66998 + 0.0268419\n",
      "[300]\tcv_agg's valid rmse: 3.66903 + 0.0255899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:  17%|#6        | 1/6 [00:08<00:41,  8.30s/it][I 2024-06-21 10:59:06,761] Trial 37 finished with value: 3.6688502365096314 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 37 with value: 3.6688502365096314.\n",
      "feature_fraction_stage2, val_score: 3.667047:  17%|#6        | 1/6 [00:08<00:41,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[295]\tcv_agg's valid rmse: 3.66885 + 0.0256947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67683 + 0.0260572\n",
      "[200]\tcv_agg's valid rmse: 3.67083 + 0.024588\n",
      "[300]\tcv_agg's valid rmse: 3.67052 + 0.0231157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:  33%|###3      | 2/6 [00:15<00:30,  7.54s/it][I 2024-06-21 10:59:13,762] Trial 38 finished with value: 3.6702022906133847 and parameters: {'feature_fraction': 0.552}. Best is trial 37 with value: 3.6688502365096314.\n",
      "feature_fraction_stage2, val_score: 3.667047:  33%|###3      | 2/6 [00:15<00:30,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[232]\tcv_agg's valid rmse: 3.6702 + 0.0235559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67587 + 0.0272492\n",
      "[200]\tcv_agg's valid rmse: 3.6693 + 0.026531\n",
      "[300]\tcv_agg's valid rmse: 3.66967 + 0.0264695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:  50%|#####     | 3/6 [00:23<00:23,  7.75s/it][I 2024-06-21 10:59:21,770] Trial 39 finished with value: 3.6690348737725964 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 37 with value: 3.6688502365096314.\n",
      "feature_fraction_stage2, val_score: 3.667047:  50%|#####     | 3/6 [00:23<00:23,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[276]\tcv_agg's valid rmse: 3.66903 + 0.0266097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67616 + 0.0284514\n",
      "[200]\tcv_agg's valid rmse: 3.6705 + 0.0258695\n",
      "[300]\tcv_agg's valid rmse: 3.6702 + 0.023951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:  67%|######6   | 4/6 [00:30<00:14,  7.47s/it][I 2024-06-21 10:59:28,805] Trial 40 finished with value: 3.669813912476024 and parameters: {'feature_fraction': 0.52}. Best is trial 37 with value: 3.6688502365096314.\n",
      "feature_fraction_stage2, val_score: 3.667047:  67%|######6   | 4/6 [00:30<00:14,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[221]\tcv_agg's valid rmse: 3.66981 + 0.0251344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67383 + 0.0278768\n",
      "[200]\tcv_agg's valid rmse: 3.6681 + 0.0264093\n",
      "[300]\tcv_agg's valid rmse: 3.6677 + 0.025748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047:  83%|########3 | 5/6 [00:38<00:07,  7.79s/it][I 2024-06-21 10:59:37,153] Trial 41 finished with value: 3.6670469345466197 and parameters: {'feature_fraction': 0.584}. Best is trial 41 with value: 3.6670469345466197.\n",
      "feature_fraction_stage2, val_score: 3.667047:  83%|########3 | 5/6 [00:38<00:07,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[273]\tcv_agg's valid rmse: 3.66705 + 0.0262964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6763 + 0.027605\n",
      "[200]\tcv_agg's valid rmse: 3.67102 + 0.0268595\n",
      "[300]\tcv_agg's valid rmse: 3.67038 + 0.0260222\n",
      "[400]\tcv_agg's valid rmse: 3.67001 + 0.026381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 3.667047: 100%|##########| 6/6 [00:48<00:00,  8.57s/it][I 2024-06-21 10:59:47,268] Trial 42 finished with value: 3.669673663041563 and parameters: {'feature_fraction': 0.616}. Best is trial 41 with value: 3.6670469345466197.\n",
      "feature_fraction_stage2, val_score: 3.667047: 100%|##########| 6/6 [00:48<00:00,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[354]\tcv_agg's valid rmse: 3.66967 + 0.026139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.667047:   0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67534 + 0.0276086\n",
      "[200]\tcv_agg's valid rmse: 3.66877 + 0.0272766\n",
      "[300]\tcv_agg's valid rmse: 3.6673 + 0.0266114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.666944:   5%|5         | 1/20 [00:08<02:37,  8.27s/it][I 2024-06-21 10:59:55,539] Trial 43 finished with value: 3.666944023861298 and parameters: {'lambda_l1': 1.3333379399135385e-07, 'lambda_l2': 5.941811936480079}. Best is trial 43 with value: 3.666944023861298.\n",
      "regularization_factors, val_score: 3.666944:   5%|5         | 1/20 [00:08<02:37,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[251]\tcv_agg's valid rmse: 3.66694 + 0.0267619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67527 + 0.0260437\n",
      "[200]\tcv_agg's valid rmse: 3.66952 + 0.0253481\n",
      "[300]\tcv_agg's valid rmse: 3.66741 + 0.0250473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.666944:  10%|#         | 2/20 [00:17<02:38,  8.81s/it][I 2024-06-21 11:00:04,732] Trial 44 finished with value: 3.6673488482840826 and parameters: {'lambda_l1': 5.3830138651497976e-08, 'lambda_l2': 2.3268221814625214}. Best is trial 43 with value: 3.666944023861298.\n",
      "regularization_factors, val_score: 3.666944:  10%|#         | 2/20 [00:17<02:38,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[288]\tcv_agg's valid rmse: 3.66735 + 0.0252839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67452 + 0.0271534\n",
      "[200]\tcv_agg's valid rmse: 3.66729 + 0.0256963\n",
      "[300]\tcv_agg's valid rmse: 3.66575 + 0.024621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.665656:  15%|#5        | 3/20 [00:26<02:33,  9.02s/it][I 2024-06-21 11:00:13,999] Trial 45 finished with value: 3.6656558951883937 and parameters: {'lambda_l1': 1.7762506065265943e-08, 'lambda_l2': 8.799271805405294}. Best is trial 45 with value: 3.6656558951883937.\n",
      "regularization_factors, val_score: 3.665656:  15%|#5        | 3/20 [00:26<02:33,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[280]\tcv_agg's valid rmse: 3.66566 + 0.0247671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67398 + 0.0267924\n",
      "[200]\tcv_agg's valid rmse: 3.66687 + 0.0249608\n",
      "[300]\tcv_agg's valid rmse: 3.66534 + 0.0242939\n",
      "[400]\tcv_agg's valid rmse: 3.66511 + 0.023929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  20%|##        | 4/20 [00:37<02:34,  9.67s/it][I 2024-06-21 11:00:24,667] Trial 46 finished with value: 3.6647563582193747 and parameters: {'lambda_l1': 1.7779192477352463e-08, 'lambda_l2': 8.04639647011756}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  20%|##        | 4/20 [00:37<02:34,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[347]\tcv_agg's valid rmse: 3.66476 + 0.0243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67452 + 0.0271537\n",
      "[200]\tcv_agg's valid rmse: 3.66731 + 0.0252105\n",
      "[300]\tcv_agg's valid rmse: 3.66646 + 0.0249101\n",
      "[400]\tcv_agg's valid rmse: 3.66633 + 0.024693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  25%|##5       | 5/20 [00:47<02:28,  9.90s/it][I 2024-06-21 11:00:34,970] Trial 47 finished with value: 3.665790895187237 and parameters: {'lambda_l1': 1.3105105019709126e-08, 'lambda_l2': 8.816027957670334}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  25%|##5       | 5/20 [00:47<02:28,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[335]\tcv_agg's valid rmse: 3.66579 + 0.0244929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67377 + 0.0266621\n",
      "[200]\tcv_agg's valid rmse: 3.66707 + 0.0264006\n",
      "[300]\tcv_agg's valid rmse: 3.66685 + 0.0259929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  30%|###       | 6/20 [00:56<02:11,  9.40s/it][I 2024-06-21 11:00:43,397] Trial 48 finished with value: 3.6665948596577542 and parameters: {'lambda_l1': 1.272251227890181e-08, 'lambda_l2': 9.171004086058531}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  30%|###       | 6/20 [00:56<02:11,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[246]\tcv_agg's valid rmse: 3.66659 + 0.0260676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67394 + 0.0267546\n",
      "[200]\tcv_agg's valid rmse: 3.66779 + 0.0263815\n",
      "[300]\tcv_agg's valid rmse: 3.66672 + 0.0260423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  35%|###5      | 7/20 [01:04<01:59,  9.21s/it][I 2024-06-21 11:00:52,215] Trial 49 finished with value: 3.6663693274736575 and parameters: {'lambda_l1': 1.466361346859532e-08, 'lambda_l2': 6.381157090894038}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  35%|###5      | 7/20 [01:04<01:59,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[267]\tcv_agg's valid rmse: 3.66637 + 0.0259428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67502 + 0.0264807\n",
      "[200]\tcv_agg's valid rmse: 3.66829 + 0.0265843\n",
      "[300]\tcv_agg's valid rmse: 3.66688 + 0.0254644\n",
      "[400]\tcv_agg's valid rmse: 3.66772 + 0.026249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  40%|####      | 8/20 [01:15<01:56,  9.68s/it][I 2024-06-21 11:01:02,898] Trial 50 finished with value: 3.666581197200891 and parameters: {'lambda_l1': 1.0867710546470511e-08, 'lambda_l2': 9.693304761531053}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  40%|####      | 8/20 [01:15<01:56,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[351]\tcv_agg's valid rmse: 3.66658 + 0.0263682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67418 + 0.0260482\n",
      "[200]\tcv_agg's valid rmse: 3.66811 + 0.0255321\n",
      "[300]\tcv_agg's valid rmse: 3.66625 + 0.0250991\n",
      "[400]\tcv_agg's valid rmse: 3.66763 + 0.0245876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  45%|####5     | 9/20 [01:25<01:47,  9.78s/it][I 2024-06-21 11:01:12,894] Trial 51 finished with value: 3.665920263662977 and parameters: {'lambda_l1': 1.1500174136482526e-08, 'lambda_l2': 7.7189179286286285}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  45%|####5     | 9/20 [01:25<01:47,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[326]\tcv_agg's valid rmse: 3.66592 + 0.0249886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67412 + 0.0265378\n",
      "[200]\tcv_agg's valid rmse: 3.66771 + 0.026433\n",
      "[300]\tcv_agg's valid rmse: 3.6672 + 0.0245807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  50%|#####     | 10/20 [01:35<01:37,  9.78s/it][I 2024-06-21 11:01:22,679] Trial 52 finished with value: 3.6669663033883717 and parameters: {'lambda_l1': 1.2124889098428528e-08, 'lambda_l2': 9.153963122933604}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  50%|#####     | 10/20 [01:35<01:37,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[297]\tcv_agg's valid rmse: 3.66697 + 0.0247294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67413 + 0.0267584\n",
      "[200]\tcv_agg's valid rmse: 3.66847 + 0.0264498\n",
      "[300]\tcv_agg's valid rmse: 3.66706 + 0.025267\n",
      "[400]\tcv_agg's valid rmse: 3.66754 + 0.0244451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  55%|#####5    | 11/20 [01:45<01:28,  9.88s/it][I 2024-06-21 11:01:32,801] Trial 53 finished with value: 3.666546372916314 and parameters: {'lambda_l1': 1.0361979402048761e-08, 'lambda_l2': 8.973750869022302}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  55%|#####5    | 11/20 [01:45<01:28,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[314]\tcv_agg's valid rmse: 3.66655 + 0.0251632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67349 + 0.0266525\n",
      "[200]\tcv_agg's valid rmse: 3.66653 + 0.0263719\n",
      "[300]\tcv_agg's valid rmse: 3.66521 + 0.0254305\n",
      "[400]\tcv_agg's valid rmse: 3.66586 + 0.0260084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  60%|######    | 12/20 [01:55<01:19,  9.99s/it][I 2024-06-21 11:01:43,022] Trial 54 finished with value: 3.664983629113999 and parameters: {'lambda_l1': 1.1814538051849173e-08, 'lambda_l2': 8.385957039344607}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  60%|######    | 12/20 [01:55<01:19,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[326]\tcv_agg's valid rmse: 3.66498 + 0.0253763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67383 + 0.0278768\n",
      "[200]\tcv_agg's valid rmse: 3.6681 + 0.0264099\n",
      "[300]\tcv_agg's valid rmse: 3.66729 + 0.0259572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  65%|######5   | 13/20 [02:04<01:07,  9.68s/it][I 2024-06-21 11:01:52,027] Trial 55 finished with value: 3.666815019485626 and parameters: {'lambda_l1': 0.0062552113825033685, 'lambda_l2': 6.170305862608674e-07}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  65%|######5   | 13/20 [02:04<01:07,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[272]\tcv_agg's valid rmse: 3.66682 + 0.0264211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6739 + 0.0273656\n",
      "[200]\tcv_agg's valid rmse: 3.6684 + 0.0260249\n",
      "[300]\tcv_agg's valid rmse: 3.66747 + 0.0246446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  70%|#######   | 14/20 [02:13<00:56,  9.35s/it][I 2024-06-21 11:02:00,581] Trial 56 finished with value: 3.6671532645375686 and parameters: {'lambda_l1': 1.7921746601336717e-06, 'lambda_l2': 0.07503149662612518}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  70%|#######   | 14/20 [02:13<00:56,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[254]\tcv_agg's valid rmse: 3.66715 + 0.0251267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67394 + 0.027177\n",
      "[200]\tcv_agg's valid rmse: 3.66849 + 0.0270828\n",
      "[300]\tcv_agg's valid rmse: 3.66787 + 0.0257055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  75%|#######5  | 15/20 [02:21<00:45,  9.15s/it][I 2024-06-21 11:02:09,264] Trial 57 finished with value: 3.667442914051274 and parameters: {'lambda_l1': 1.6913109397132856e-06, 'lambda_l2': 0.14155835454240945}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  75%|#######5  | 15/20 [02:21<00:45,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[256]\tcv_agg's valid rmse: 3.66744 + 0.0268068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.675 + 0.0277324\n",
      "[200]\tcv_agg's valid rmse: 3.66898 + 0.0275684\n",
      "[300]\tcv_agg's valid rmse: 3.66952 + 0.0260213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  80%|########  | 16/20 [02:30<00:35,  8.96s/it][I 2024-06-21 11:02:17,796] Trial 58 finished with value: 3.668886554719277 and parameters: {'lambda_l1': 4.496186292675216, 'lambda_l2': 0.21204243751578286}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  80%|########  | 16/20 [02:30<00:35,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[226]\tcv_agg's valid rmse: 3.66889 + 0.0276024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67462 + 0.0277187\n",
      "[200]\tcv_agg's valid rmse: 3.66804 + 0.0261775\n",
      "[300]\tcv_agg's valid rmse: 3.66665 + 0.0260925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  85%|########5 | 17/20 [02:40<00:27,  9.15s/it][I 2024-06-21 11:02:27,378] Trial 59 finished with value: 3.666592928400971 and parameters: {'lambda_l1': 3.063461342488489e-07, 'lambda_l2': 0.3470041140728565}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  85%|########5 | 17/20 [02:40<00:27,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[286]\tcv_agg's valid rmse: 3.66659 + 0.0260378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67345 + 0.0283969\n",
      "[200]\tcv_agg's valid rmse: 3.66754 + 0.0275519\n",
      "[300]\tcv_agg's valid rmse: 3.66695 + 0.026075\n",
      "[400]\tcv_agg's valid rmse: 3.6668 + 0.024933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  90%|######### | 18/20 [02:50<00:18,  9.45s/it][I 2024-06-21 11:02:37,545] Trial 60 finished with value: 3.666345662040503 and parameters: {'lambda_l1': 1.732578376681285e-07, 'lambda_l2': 0.8346201952756508}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  90%|######### | 18/20 [02:50<00:18,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[329]\tcv_agg's valid rmse: 3.66635 + 0.0258381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67425 + 0.0268925\n",
      "[200]\tcv_agg's valid rmse: 3.66769 + 0.0258417\n",
      "[300]\tcv_agg's valid rmse: 3.66783 + 0.025098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756:  95%|#########5| 19/20 [02:58<00:09,  9.18s/it][I 2024-06-21 11:02:46,083] Trial 61 finished with value: 3.6672484642142686 and parameters: {'lambda_l1': 1.2903577106152374e-08, 'lambda_l2': 1.1427326778183697}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756:  95%|#########5| 19/20 [02:58<00:09,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[257]\tcv_agg's valid rmse: 3.66725 + 0.0255629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67407 + 0.0267024\n",
      "[200]\tcv_agg's valid rmse: 3.66744 + 0.0258709\n",
      "[300]\tcv_agg's valid rmse: 3.66657 + 0.0255863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 3.664756: 100%|##########| 20/20 [03:08<00:00,  9.31s/it][I 2024-06-21 11:02:55,709] Trial 62 finished with value: 3.6665684177568414 and parameters: {'lambda_l1': 7.641872509686887e-08, 'lambda_l2': 1.6565783145856767}. Best is trial 46 with value: 3.6647563582193747.\n",
      "regularization_factors, val_score: 3.664756: 100%|##########| 20/20 [03:08<00:00,  9.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tcv_agg's valid rmse: 3.66793 + 0.0252895\n",
      "Early stopping, best iteration is:\n",
      "[300]\tcv_agg's valid rmse: 3.66657 + 0.0255863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664756:   0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67247 + 0.0270858\n",
      "[200]\tcv_agg's valid rmse: 3.66582 + 0.0262272\n",
      "[300]\tcv_agg's valid rmse: 3.66439 + 0.0255272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664290:  20%|##        | 1/5 [00:09<00:36,  9.21s/it][I 2024-06-21 11:03:04,915] Trial 63 finished with value: 3.6642902997637306 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 3.6642902997637306.\n",
      "min_child_samples, val_score: 3.664290:  20%|##        | 1/5 [00:09<00:36,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[279]\tcv_agg's valid rmse: 3.66429 + 0.0256625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67305 + 0.0270901\n",
      "[200]\tcv_agg's valid rmse: 3.66622 + 0.0261666\n",
      "[300]\tcv_agg's valid rmse: 3.66552 + 0.0256173\n",
      "[400]\tcv_agg's valid rmse: 3.6652 + 0.0246805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664290:  40%|####      | 2/5 [00:19<00:29,  9.94s/it][I 2024-06-21 11:03:15,361] Trial 64 finished with value: 3.6649777500482394 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 3.6642902997637306.\n",
      "min_child_samples, val_score: 3.664290:  40%|####      | 2/5 [00:19<00:29,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[337]\tcv_agg's valid rmse: 3.66498 + 0.0250996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67404 + 0.0267607\n",
      "[200]\tcv_agg's valid rmse: 3.66846 + 0.0263524\n",
      "[300]\tcv_agg's valid rmse: 3.66712 + 0.0259797\n",
      "[400]\tcv_agg's valid rmse: 3.66728 + 0.0251837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664290:  60%|######    | 3/5 [00:29<00:19,  9.92s/it][I 2024-06-21 11:03:25,265] Trial 65 finished with value: 3.6667108403694852 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 3.6642902997637306.\n",
      "min_child_samples, val_score: 3.664290:  60%|######    | 3/5 [00:29<00:19,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[323]\tcv_agg's valid rmse: 3.66671 + 0.0261323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.6746 + 0.0272908\n",
      "[200]\tcv_agg's valid rmse: 3.66773 + 0.0254825\n",
      "[300]\tcv_agg's valid rmse: 3.66718 + 0.0252872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664290:  80%|########  | 4/5 [00:37<00:09,  9.30s/it][I 2024-06-21 11:03:33,603] Trial 66 finished with value: 3.666563942349464 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 3.6642902997637306.\n",
      "min_child_samples, val_score: 3.664290:  80%|########  | 4/5 [00:37<00:09,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[247]\tcv_agg's valid rmse: 3.66656 + 0.0251336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:91: UserWarning: The groups parameter is ignored by KFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8665\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.394844\n",
      "[LightGBM] [Info] Start training from score -0.394605\n",
      "[LightGBM] [Info] Start training from score -0.391206\n",
      "[LightGBM] [Info] Start training from score -0.395780\n",
      "[LightGBM] [Info] Start training from score -0.391748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tcv_agg's valid rmse: 3.67283 + 0.0277311\n",
      "[200]\tcv_agg's valid rmse: 3.66548 + 0.0271962\n",
      "[300]\tcv_agg's valid rmse: 3.66453 + 0.0266251\n",
      "[400]\tcv_agg's valid rmse: 3.66521 + 0.0263405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 3.664290: 100%|##########| 5/5 [00:48<00:00,  9.64s/it][I 2024-06-21 11:03:43,853] Trial 67 finished with value: 3.6643594697366857 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 3.6642902997637306.\n",
      "min_child_samples, val_score: 3.664290: 100%|##########| 5/5 [00:48<00:00,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[336]\tcv_agg's valid rmse: 3.66436 + 0.0271613\n",
      "  Params: \n",
      "    objective: regression\n",
      "    metric: rmse\n",
      "    learning_rate: 0.1\n",
      "    random_seed: 0\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 1.7779192477352463e-08\n",
      "    lambda_l2: 8.04639647011756\n",
      "    num_leaves: 7\n",
      "    feature_fraction: 0.6\n",
      "    bagging_fraction: 0.999528917168157\n",
      "    bagging_freq: 5\n",
      "    min_child_samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optunaによるハイパーパラメータの探索\n",
    "\n",
    "\n",
    "# 特徴量選択\n",
    "train_selected = train_.iloc[:,feat_selector.support_]\n",
    "# LightGBM用のデータセットに変換\n",
    "trainval = lgb.Dataset(train_selected, target)\n",
    "\n",
    "# ハイパーパラメータサーチ&モデル構築\n",
    "params = {'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'learning_rate': 0.1,\n",
    "          'random_seed':0}\n",
    "\n",
    "# クロスバリデーションによるハイパーパラメータの探索 3fold\n",
    "tuner = lgbo.LightGBMTunerCV(params, trainval, callbacks=[early_stopping(100), log_evaluation(100)], folds=KFold(n_splits=5), optuna_seed=0)\n",
    "\n",
    "# ハイパーパラメータ探索の実行\n",
    "tuner.run()\n",
    "\n",
    "# サーチしたパラメータの表示\n",
    "best_params = tuner.best_params\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の情報\n",
    "features = [c for c in train_selected.columns if c not in ['card_id', 'first_active_month']]\n",
    "# categorical_feats = ['feature_2', 'feature_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここから実行すればOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'objective': 'regression',\n",
    " 'metric': 'rmse',\n",
    " 'learning_rate': 0.1,\n",
    " 'random_seed': 0,\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 1.7779192477352463e-08,\n",
    " 'lambda_l2': 8.04639647011756,\n",
    " 'num_leaves': 7,\n",
    " 'feature_fraction': 0.6,\n",
    " 'bagging_fraction': 0.999528917168157,\n",
    " 'bagging_freq': 5,\n",
    " 'min_child_samples': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['elapsed_time', 'hist_category_1_sum', 'hist_installments_sum',\n",
    " 'hist_purchase_date_ptp', 'hist_purchase_date_min', 'hist_month_diff_mean',\n",
    " 'hist_merchant_avg_purchases_lag3_sum', 'hist_merchant_active_months_lag12_sum',\n",
    " 'auth_category_1_sum', 'auth_category_1_mean', 'auth_purchase_amount_sum',\n",
    " 'auth_installments_sum', 'auth_purchase_month_std', 'auth_purchase_date_ptp',\n",
    " 'auth_purchase_date_min', 'auth_purchase_date_max', 'auth_month_lag_mean',\n",
    " 'auth_month_diff_mean', 'auth_merchant_group_id_nunique',\n",
    " 'auth_merchant_avg_purchases_lag3_min', 'new_category_1_sum',\n",
    " 'new_category_1_mean', 'new_purchase_amount_sum', 'new_purchase_amount_mean',\n",
    " 'new_purchase_amount_max', 'new_purchase_amount_std', 'new_purchase_month_mean',\n",
    " 'new_purchase_date_ptp', 'new_purchase_date_min', 'new_purchase_date_max',\n",
    " 'new_month_lag_mean', 'new_merchant_avg_purchases_lag6_sum', 'month_lag_std',\n",
    " 'purchase_amount_count_mean', 'purchase_amount_mean_mean',\n",
    " 'purchase_amount_max_mean', 'authorized_flag_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8637\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.393503\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.65206\n",
      "[200]\tvalid_0's rmse: 3.64334\n",
      "[300]\tvalid_0's rmse: 3.64127\n",
      "[400]\tvalid_0's rmse: 3.64076\n",
      "[500]\tvalid_0's rmse: 3.64141\n",
      "[600]\tvalid_0's rmse: 3.64052\n",
      "Early stopping, best iteration is:\n",
      "[453]\tvalid_0's rmse: 3.64002\n",
      "fold n°1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8643\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.390165\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.70837\n",
      "[200]\tvalid_0's rmse: 3.7007\n",
      "[300]\tvalid_0's rmse: 3.6975\n",
      "[400]\tvalid_0's rmse: 3.69734\n",
      "[500]\tvalid_0's rmse: 3.69693\n",
      "[600]\tvalid_0's rmse: 3.69833\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's rmse: 3.69607\n",
      "fold n°2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8645\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.396571\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.66577\n",
      "[200]\tvalid_0's rmse: 3.66007\n",
      "[300]\tvalid_0's rmse: 3.65736\n",
      "[400]\tvalid_0's rmse: 3.65626\n",
      "[500]\tvalid_0's rmse: 3.65721\n",
      "[600]\tvalid_0's rmse: 3.65785\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's rmse: 3.65586\n",
      "fold n°3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8638\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.397611\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.63445\n",
      "[200]\tvalid_0's rmse: 3.62891\n",
      "[300]\tvalid_0's rmse: 3.63035\n",
      "[400]\tvalid_0's rmse: 3.632\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's rmse: 3.62839\n",
      "fold n°4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8644\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -0.390331\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.71488\n",
      "[200]\tvalid_0's rmse: 3.70439\n",
      "[300]\tvalid_0's rmse: 3.70414\n",
      "[400]\tvalid_0's rmse: 3.70561\n",
      "[500]\tvalid_0's rmse: 3.70735\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid_0's rmse: 3.70385\n"
     ]
    }
   ],
   "source": [
    "#lightgbm\n",
    "# データをKFoldで5分割して学習\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "        label=target.iloc[trn_idx],\n",
    "    )\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "        label=target.iloc[val_idx],\n",
    "    )\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(params=best_params,\n",
    "                    train_set=trn_data,\n",
    "                    num_boost_round=num_round,\n",
    "                    valid_sets=[val_data],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200),\n",
    "                            lgb.log_evaluation(100)])\n",
    "\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # モデルを保存\n",
    "    with open(f'../src/models/model_fold_{fold_}.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 3.66897 \n"
     ]
    }
   ],
   "source": [
    "oof = np.where(oof < -17, errvalue, oof)\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x5000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 特徴量重要度の可視化\n",
    "\n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,50))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('lgbm_importances.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
