{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions = pd.read_csv('../data/row/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/row/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions = historical_transactions[['authorized_flag', 'card_id', 'purchase_amount', 'purchase_date']]\n",
    "new_transactions = new_transactions[['authorized_flag', 'card_id', 'purchase_amount', 'purchase_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 583.04 Mb (34.4% reduction)\n",
      "Mem. usage decreased to 35.57 Mb (40.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# 日付を三角関数変換し、新しいデータフレームとして取得する関数\n",
    "def get_trigonometrical_date(df):\n",
    "    # df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "\n",
    "    # 年ごとの日数を計算\n",
    "    years = df['purchase_date'].dt.year\n",
    "    unique_years = years.unique()\n",
    "    days_in_year_dict = {year: (datetime(year + 1, 1, 1) - datetime(year, 1, 1)).days for year in unique_years}\n",
    "    days_in_year = years.map(days_in_year_dict).to_numpy()\n",
    "\n",
    "    # 年の日数に基づいて日をエンコード\n",
    "    day_of_year = df['purchase_date'].dt.dayofyear.to_numpy()\n",
    "    day_of_year_sin = np.sin(2 * np.pi * day_of_year / days_in_year)\n",
    "    day_of_year_cos = np.cos(2 * np.pi * day_of_year / days_in_year)\n",
    "\n",
    "    # 曜日をエンコード\n",
    "    day_of_week = df['purchase_date'].dt.weekday.to_numpy()\n",
    "    day_of_week_sin = np.sin(2 * np.pi * day_of_week / 7)\n",
    "    day_of_week_cos = np.cos(2 * np.pi * day_of_week / 7)\n",
    "\n",
    "    # 一か月の周期をエンコード（各月の最大日数を使用）\n",
    "    days_in_month = df['purchase_date'].apply(lambda date: calendar.monthrange(date.year, date.month)[1]).to_numpy()\n",
    "    day_of_month = df['purchase_date'].dt.day.to_numpy()\n",
    "    day_of_month_sin = np.sin(2 * np.pi * day_of_month / days_in_month)\n",
    "    day_of_month_cos = np.cos(2 * np.pi * day_of_month / days_in_month)\n",
    "\n",
    "    # 一日の周期（時刻）をエンコード\n",
    "    hour_of_day = df['purchase_date'].dt.hour + df['purchase_date'].dt.minute / 60.0\n",
    "    hour_of_day_sin = np.sin(2 * np.pi * hour_of_day / 24)\n",
    "    hour_of_day_cos = np.cos(2 * np.pi * hour_of_day / 24)\n",
    "\n",
    "    # 結果をデータフレームに追加\n",
    "    date_trigonometry = pd.DataFrame({\n",
    "        'day_of_year': day_of_year,\n",
    "        'day_of_year_sin': day_of_year_sin,\n",
    "        'day_of_year_cos': day_of_year_cos,\n",
    "        'day_of_month': day_of_month,\n",
    "        'day_of_month_sin': day_of_month_sin,\n",
    "        'day_of_month_cos': day_of_month_cos,\n",
    "        'day_of_week': day_of_week,\n",
    "        'day_of_week_sin': day_of_week_sin,\n",
    "        'day_of_week_cos': day_of_week_cos,\n",
    "        'hour_of_day': hour_of_day,\n",
    "        'hour_of_day_sin': hour_of_day_sin,\n",
    "        'hour_of_day_cos': hour_of_day_cos\n",
    "    })\n",
    "\n",
    "    return date_trigonometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions_sin = new_transactions.join(get_trigonometrical_date(new_transactions))\n",
    "historical_transactions_sin = historical_transactions.join(get_trigonometrical_date(historical_transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1193.84 Mb (59.0% reduction)\n",
      "Mem. usage decreased to 76.76 Mb (60.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "# メモリ使用量の削減\n",
    "historical_transactions_sin = reduce_mem_usage(historical_transactions_sin)\n",
    "new_transactions_sin = reduce_mem_usage(new_transactions_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase_month列を追加\n",
    "\n",
    "historical_transactions_sin['purchase_month'] = historical_transactions_sin['purchase_date'].dt.to_period('M').dt.to_timestamp()\n",
    "new_transactions_sin['purchase_month'] = new_transactions_sin['purchase_date'].dt.to_period('M').dt.to_timestamp()\n",
    "historical_transactions_sin['purchase_year'] = historical_transactions_sin['purchase_date'].dt.year\n",
    "new_transactions_sin['purchase_year'] = new_transactions_sin['purchase_date'].dt.year\n",
    "historical_transactions_sin['epoch'] = pd.DatetimeIndex(historical_transactions_sin['purchase_date']).astype(np.int64) * 1e-9\n",
    "new_transactions_sin['epoch'] = pd.DatetimeIndex(new_transactions_sin['purchase_date']).astype(np.int64) * 1e-9\n",
    "\n",
    "\n",
    "all_transactions = pd.concat([historical_transactions_sin, new_transactions_sin], axis=0).reset_index(drop=True)\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions_sin[historical_transactions_sin['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions_sin[historical_transactions_sin['authorized_flag'] == 0]\n",
    "new_transactions = new_transactions_sin.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1689.24 Mb (9.5% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1597.89 Mb (11.3% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 156.02 Mb (8.5% reduction)\n",
      "Mem. usage decreased to 102.97 Mb (9.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "all_transactions = reduce_mem_usage(all_transactions)\n",
    "authorized_transactions = reduce_mem_usage(authorized_transactions)\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\112637800.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  authorized_transactions['purchase_amount'] = authorized_transactions['purchase_amount'].astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "authorized_transactions['purchase_amount'] = authorized_transactions['purchase_amount'].astype(np.float32)\n",
    "new_transactions['purchase_amount'] = new_transactions['purchase_amount'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_transactions_sin\n",
    "del historical_transactions_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value1(df, suf=None):\n",
    "    valuelist = ['day_of_year', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'purchase_year', 'epoch']\n",
    "    valuelistwc = ['card_id', 'day_of_year', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'purchase_year', 'epoch']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "    for mode in ['max', 'min', 'old', 'new']:\n",
    "        if mode == 'max':\n",
    "            amt_idx = df.groupby('card_id')['purchase_amount'].idxmax()\n",
    "        elif mode == 'min':\n",
    "            amt_idx = df.groupby('card_id')['purchase_amount'].idxmin()\n",
    "        elif mode == 'old':\n",
    "            amt_idx = df.groupby('card_id')['purchase_date'].idxmin()\n",
    "        elif mode == 'new':\n",
    "            amt_idx = df.groupby('card_id')['purchase_date'].idxmax()\n",
    "        kari_add_df = pd.merge(kari_add_df, df.loc[amt_idx, valuelistwc], how='left', on='card_id', suffixes=['', ('_' + suf + mode)])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーごとの最高額、最低額、最初の決済、最後の決済の日時情報\n",
    "add_df = all_transactions.card_id.drop_duplicates()\n",
    "add_df = pd.merge(add_df,value1(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(new_transactions, 'new'), on='card_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value2(df, suf=None):\n",
    "    valuelist = ['day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'epoch']\n",
    "    valuelistwc = ['card_id','day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'epoch']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "\n",
    "    for mode in ['allmean', 'newmean', 'maxmean']:\n",
    "        if mode == 'allmean':\n",
    "            dfagg = df.groupby('card_id').mean()[valuelist]\n",
    "        elif mode == 'newmean':\n",
    "            a = df.groupby('card_id')['purchase_month'].max()\n",
    "            dfagg = df.merge(a, how='inner', on=['card_id', 'purchase_month']).groupby('card_id').mean()[valuelist]\n",
    "        elif mode == 'maxmean':\n",
    "            a = df.groupby(['card_id', 'purchase_month'])['purchase_amount'].sum().reset_index()\n",
    "            dfagg = df.merge(a.loc[a.groupby('card_id')['purchase_amount'].idxmax()][['card_id', 'purchase_month']], how='inner', on=['card_id', 'purchase_month']).groupby('card_id').mean()[valuelist]\n",
    "        # elif mode == 'allmode':\n",
    "        #     amt_idx = df.groupby('card_id')['purchase_date'].idxmax()\n",
    "        kari_add_df = pd.merge(kari_add_df, dfagg, how='left', on='card_id', suffixes=['', ('_' + suf + mode)])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーごとの全期間、最新月、決済金額合計が最大となる月それぞれの平均日時情報\n",
    "add_df = pd.merge(add_df,value2(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(new_transactions, 'new'), on='card_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value3(df, suf=None):\n",
    "    valuelist = ['day_of_week', 'purchase_year', 'purchase_month']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "    dfagg = df.groupby('card_id')[valuelist].apply(lambda x: x.mode()).reset_index().groupby('card_id')[valuelist].max()\n",
    "    kari_add_df = pd.merge(kari_add_df, dfagg, how='left', on='card_id', suffixes=['', ('_' + suf + 'allmode')])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.merge(add_df,value3(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(new_transactions, 'new'), on='card_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['purchase_amount'] < row['Q1']:\n",
    "        return 'under25_mean'\n",
    "    elif row['purchase_amount'] > row['Q3']:\n",
    "        return 'up25_mean'\n",
    "    else:\n",
    "        return '25-75_mean'\n",
    "\n",
    "def value4(df, suf=None):\n",
    "\n",
    "    kari_add_df = df.groupby('card_id').purchase_date.count().rename('purchase_count')\n",
    "\n",
    "    percentiles = df.groupby('card_id')['purchase_amount'].quantile([0.25, 0.75]).unstack(level=1)\n",
    "    percentiles.columns = ['Q1', 'Q3']\n",
    "    dff = pd.merge(df, percentiles, on='card_id', how='left')\n",
    "    dff['amount_rank'] = dff.apply(categorize, axis=1)\n",
    "\n",
    "    kari_add_df = pd.merge(kari_add_df, dff.groupby(['card_id', 'amount_rank'])['purchase_amount'].mean().unstack(), on='card_id', how='left')\n",
    "    kari_add_df['diff_up25-2575'] = kari_add_df['up25_mean'] - kari_add_df['25-75_mean']\n",
    "    kari_add_df['diff_2575-under25'] = kari_add_df['25-75_mean'] - kari_add_df['under25_mean']\n",
    "    kari_add_df['diff_up25-under25'] = kari_add_df['up25_mean'] - kari_add_df['under25_mean']\n",
    "    kari_add_df['ratio_up25/2575'] = kari_add_df['up25_mean'] / kari_add_df['25-75_mean']\n",
    "    kari_add_df['ratio_under25/2575'] = kari_add_df['under25_mean'] / kari_add_df['25-75_mean']\n",
    "    return kari_add_df.add_suffix('_' + suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.merge(add_df,value4(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value4(authorized_transactions, 'auth'), on='card_id', how='left')\n",
    "add_df = pd.merge(add_df,value4(historical_transactions, 'hist'), on='card_id', how='left')\n",
    "add_df = pd.merge(add_df,value4(new_transactions, 'new'), on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = read_data('../data/processed/processed20240625_train.csv')\n",
    "test = read_data('../data/processed/processed20240625_test.csv')\n",
    "\n",
    "\n",
    "train = pd.merge(train, add_df, on='card_id', how='left')\n",
    "test = pd.merge(test, add_df, on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>day_of_year_allmax</th>\n",
       "      <th>day_of_year_sin_allmax</th>\n",
       "      <th>day_of_year_cos_allmax</th>\n",
       "      <th>day_of_month_allmax</th>\n",
       "      <th>day_of_month_sin_allmax</th>\n",
       "      <th>day_of_month_cos_allmax</th>\n",
       "      <th>day_of_week_allmax</th>\n",
       "      <th>day_of_week_sin_allmax</th>\n",
       "      <th>day_of_week_cos_allmax</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_under25/2575_hist</th>\n",
       "      <th>purchase_count_new</th>\n",
       "      <th>25-75_mean_new</th>\n",
       "      <th>under25_mean_new</th>\n",
       "      <th>up25_mean_new</th>\n",
       "      <th>diff_up25-2575_new</th>\n",
       "      <th>diff_2575-under25_new</th>\n",
       "      <th>diff_up25-under25_new</th>\n",
       "      <th>ratio_up25/2575_new</th>\n",
       "      <th>ratio_under25/2575_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>15</td>\n",
       "      <td>0.255371</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>15</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>-0.994629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.102842</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.649414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.703125</td>\n",
       "      <td>-0.053711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.082707</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_5037ff576e</td>\n",
       "      <td>208</td>\n",
       "      <td>-0.425049</td>\n",
       "      <td>-0.905273</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.724609</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>3</td>\n",
       "      <td>0.433838</td>\n",
       "      <td>-0.900879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542981</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.356445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334961</td>\n",
       "      <td>-1.021484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246940</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0e171c1b48</td>\n",
       "      <td>100</td>\n",
       "      <td>0.988770</td>\n",
       "      <td>-0.150024</td>\n",
       "      <td>10</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.420394</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.141846</td>\n",
       "      <td>-0.699097</td>\n",
       "      <td>-0.733765</td>\n",
       "      <td>-0.591919</td>\n",
       "      <td>0.557251</td>\n",
       "      <td>-0.034668</td>\n",
       "      <td>5.172977</td>\n",
       "      <td>4.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_48fb13e70f</td>\n",
       "      <td>158</td>\n",
       "      <td>0.409424</td>\n",
       "      <td>-0.912598</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994629</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>-0.222534</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_fc8e41b9cf</td>\n",
       "      <td>192</td>\n",
       "      <td>-0.162842</td>\n",
       "      <td>-0.986816</td>\n",
       "      <td>11</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.836690</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.343259</td>\n",
       "      <td>-0.586093</td>\n",
       "      <td>-0.703809</td>\n",
       "      <td>-1.047067</td>\n",
       "      <td>0.929352</td>\n",
       "      <td>-0.117716</td>\n",
       "      <td>-2.050374</td>\n",
       "      <td>-1.707438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325535</th>\n",
       "      <td>C_ID_803aa0aed4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.421143</td>\n",
       "      <td>7</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>-0.222534</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.549316</td>\n",
       "      <td>-0.663965</td>\n",
       "      <td>-0.727539</td>\n",
       "      <td>-0.178223</td>\n",
       "      <td>0.114648</td>\n",
       "      <td>-0.063574</td>\n",
       "      <td>1.324444</td>\n",
       "      <td>1.208711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325536</th>\n",
       "      <td>C_ID_62df280b20</td>\n",
       "      <td>261</td>\n",
       "      <td>-0.976074</td>\n",
       "      <td>-0.217773</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.587891</td>\n",
       "      <td>-0.809082</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.110352</td>\n",
       "      <td>-0.572021</td>\n",
       "      <td>-0.641602</td>\n",
       "      <td>-0.751953</td>\n",
       "      <td>0.682373</td>\n",
       "      <td>-0.069580</td>\n",
       "      <td>-5.814159</td>\n",
       "      <td>-5.183628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325537</th>\n",
       "      <td>C_ID_e49b1996b0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>13</td>\n",
       "      <td>0.485352</td>\n",
       "      <td>-0.874512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781738</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.617676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325538</th>\n",
       "      <td>C_ID_2863d2fa95</td>\n",
       "      <td>20</td>\n",
       "      <td>0.337402</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.791016</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.433838</td>\n",
       "      <td>-0.900879</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325539</th>\n",
       "      <td>C_ID_5c240d6e3c</td>\n",
       "      <td>299</td>\n",
       "      <td>-0.907227</td>\n",
       "      <td>0.421143</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.848633</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.433838</td>\n",
       "      <td>-0.900879</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.473511</td>\n",
       "      <td>-0.690104</td>\n",
       "      <td>-0.735840</td>\n",
       "      <td>-0.262329</td>\n",
       "      <td>0.216593</td>\n",
       "      <td>-0.045736</td>\n",
       "      <td>1.554009</td>\n",
       "      <td>1.457420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325540 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id  day_of_year_allmax  day_of_year_sin_allmax  \\\n",
       "0       C_ID_4e6213e9bc                  15                0.255371   \n",
       "1       C_ID_5037ff576e                 208               -0.425049   \n",
       "2       C_ID_0e171c1b48                 100                0.988770   \n",
       "3       C_ID_48fb13e70f                 158                0.409424   \n",
       "4       C_ID_fc8e41b9cf                 192               -0.162842   \n",
       "...                 ...                 ...                     ...   \n",
       "325535  C_ID_803aa0aed4                  66                0.907227   \n",
       "325536  C_ID_62df280b20                 261               -0.976074   \n",
       "325537  C_ID_e49b1996b0                  72                0.945801   \n",
       "325538  C_ID_2863d2fa95                  20                0.337402   \n",
       "325539  C_ID_5c240d6e3c                 299               -0.907227   \n",
       "\n",
       "        day_of_year_cos_allmax  day_of_month_allmax  day_of_month_sin_allmax  \\\n",
       "0                     0.966797                   15                 0.101196   \n",
       "1                    -0.905273                   27                -0.724609   \n",
       "2                    -0.150024                   10                 0.866211   \n",
       "3                    -0.912598                    7                 0.994629   \n",
       "4                    -0.986816                   11                 0.791016   \n",
       "...                        ...                  ...                      ...   \n",
       "325535                0.421143                    7                 0.988281   \n",
       "325536               -0.217773                   18                -0.587891   \n",
       "325537                0.325439                   13                 0.485352   \n",
       "325538                0.941406                   20                -0.791016   \n",
       "325539                0.421143                   26                -0.848633   \n",
       "\n",
       "        day_of_month_cos_allmax  day_of_week_allmax  day_of_week_sin_allmax  \\\n",
       "0                     -0.994629                   0                0.000000   \n",
       "1                      0.688965                   3                0.433838   \n",
       "2                     -0.500000                   1                0.781738   \n",
       "3                      0.104553                   2                0.975098   \n",
       "4                     -0.612305                   1                0.781738   \n",
       "...                         ...                 ...                     ...   \n",
       "325535                 0.151367                   2                0.975098   \n",
       "325536                -0.809082                   0                0.000000   \n",
       "325537                -0.874512                   1                0.781738   \n",
       "325538                -0.612305                   4               -0.433838   \n",
       "325539                 0.528809                   3                0.433838   \n",
       "\n",
       "        day_of_week_cos_allmax  ...  ratio_under25/2575_hist  \\\n",
       "0                     1.000000  ...                 1.102842   \n",
       "1                    -0.900879  ...                 0.542981   \n",
       "2                     0.623535  ...                 1.420394   \n",
       "3                    -0.222534  ...                      NaN   \n",
       "4                     0.623535  ...                -0.836690   \n",
       "...                        ...  ...                      ...   \n",
       "325535               -0.222534  ...                      NaN   \n",
       "325536                1.000000  ...                      NaN   \n",
       "325537                0.623535  ...                      NaN   \n",
       "325538               -0.900879  ...                      NaN   \n",
       "325539               -0.900879  ...                      NaN   \n",
       "\n",
       "        purchase_count_new  25-75_mean_new  under25_mean_new  up25_mean_new  \\\n",
       "0                      2.0       -0.649414               NaN      -0.703125   \n",
       "1                      2.0        1.356445               NaN       0.334961   \n",
       "2                     16.0       -0.141846         -0.699097      -0.733765   \n",
       "3                      1.0             NaN         -0.446289            NaN   \n",
       "4                     21.0        0.343259         -0.586093      -0.703809   \n",
       "...                    ...             ...               ...            ...   \n",
       "325535                 9.0       -0.549316         -0.663965      -0.727539   \n",
       "325536                 4.0        0.110352         -0.572021      -0.641602   \n",
       "325537                 1.0             NaN         -0.617676            NaN   \n",
       "325538                 NaN             NaN               NaN            NaN   \n",
       "325539                 7.0       -0.473511         -0.690104      -0.735840   \n",
       "\n",
       "        diff_up25-2575_new  diff_2575-under25_new  diff_up25-under25_new  \\\n",
       "0                -0.053711                    NaN                    NaN   \n",
       "1                -1.021484                    NaN                    NaN   \n",
       "2                -0.591919               0.557251              -0.034668   \n",
       "3                      NaN                    NaN                    NaN   \n",
       "4                -1.047067               0.929352              -0.117716   \n",
       "...                    ...                    ...                    ...   \n",
       "325535           -0.178223               0.114648              -0.063574   \n",
       "325536           -0.751953               0.682373              -0.069580   \n",
       "325537                 NaN                    NaN                    NaN   \n",
       "325538                 NaN                    NaN                    NaN   \n",
       "325539           -0.262329               0.216593              -0.045736   \n",
       "\n",
       "        ratio_up25/2575_new  ratio_under25/2575_new  \n",
       "0                  1.082707                     NaN  \n",
       "1                  0.246940                     NaN  \n",
       "2                  5.172977                4.928571  \n",
       "3                       NaN                     NaN  \n",
       "4                 -2.050374               -1.707438  \n",
       "...                     ...                     ...  \n",
       "325535             1.324444                1.208711  \n",
       "325536            -5.814159               -5.183628  \n",
       "325537                  NaN                     NaN  \n",
       "325538                  NaN                     NaN  \n",
       "325539             1.554009                1.457420  \n",
       "\n",
       "[325540 rows x 393 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240627_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240627_test.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
