{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions = pd.read_csv('../data/row/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/row/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions = historical_transactions[['authorized_flag', 'card_id', 'purchase_amount', 'purchase_date']]\n",
    "new_transactions = new_transactions[['authorized_flag', 'card_id', 'purchase_amount', 'purchase_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 583.04 Mb (34.4% reduction)\n",
      "Mem. usage decreased to 35.57 Mb (40.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# 日付を三角関数変換し、新しいデータフレームとして取得する関数\n",
    "def get_trigonometrical_date(df):\n",
    "    # df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "\n",
    "    # 年ごとの日数を計算\n",
    "    years = df['purchase_date'].dt.year\n",
    "    unique_years = years.unique()\n",
    "    days_in_year_dict = {year: (datetime(year + 1, 1, 1) - datetime(year, 1, 1)).days for year in unique_years}\n",
    "    days_in_year = years.map(days_in_year_dict).to_numpy()\n",
    "\n",
    "    # 年の日数に基づいて日をエンコード\n",
    "    day_of_year = df['purchase_date'].dt.dayofyear.to_numpy()\n",
    "    day_of_year_sin = np.sin(2 * np.pi * day_of_year / days_in_year)\n",
    "    day_of_year_cos = np.cos(2 * np.pi * day_of_year / days_in_year)\n",
    "\n",
    "    # 曜日をエンコード\n",
    "    day_of_week = df['purchase_date'].dt.weekday.to_numpy()\n",
    "    day_of_week_sin = np.sin(2 * np.pi * day_of_week / 7)\n",
    "    day_of_week_cos = np.cos(2 * np.pi * day_of_week / 7)\n",
    "\n",
    "    # 一か月の周期をエンコード（各月の最大日数を使用）\n",
    "    days_in_month = df['purchase_date'].apply(lambda date: calendar.monthrange(date.year, date.month)[1]).to_numpy()\n",
    "    day_of_month = df['purchase_date'].dt.day.to_numpy()\n",
    "    day_of_month_sin = np.sin(2 * np.pi * day_of_month / days_in_month)\n",
    "    day_of_month_cos = np.cos(2 * np.pi * day_of_month / days_in_month)\n",
    "\n",
    "    # 一日の周期（時刻）をエンコード\n",
    "    hour_of_day = df['purchase_date'].dt.hour + df['purchase_date'].dt.minute / 60.0\n",
    "    hour_of_day_sin = np.sin(2 * np.pi * hour_of_day / 24)\n",
    "    hour_of_day_cos = np.cos(2 * np.pi * hour_of_day / 24)\n",
    "\n",
    "    # 結果をデータフレームに追加\n",
    "    date_trigonometry = pd.DataFrame({\n",
    "        'day_of_year': day_of_year,\n",
    "        'day_of_year_sin': day_of_year_sin,\n",
    "        'day_of_year_cos': day_of_year_cos,\n",
    "        'day_of_month': day_of_month,\n",
    "        'day_of_month_sin': day_of_month_sin,\n",
    "        'day_of_month_cos': day_of_month_cos,\n",
    "        'day_of_week': day_of_week,\n",
    "        'day_of_week_sin': day_of_week_sin,\n",
    "        'day_of_week_cos': day_of_week_cos,\n",
    "        'hour_of_day': hour_of_day,\n",
    "        'hour_of_day_sin': hour_of_day_sin,\n",
    "        'hour_of_day_cos': hour_of_day_cos\n",
    "    })\n",
    "\n",
    "    return date_trigonometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions_sin = new_transactions.join(get_trigonometrical_date(new_transactions))\n",
    "historical_transactions_sin = historical_transactions.join(get_trigonometrical_date(historical_transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1193.84 Mb (59.0% reduction)\n",
      "Mem. usage decreased to 76.76 Mb (60.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "# メモリ使用量の削減\n",
    "historical_transactions_sin = reduce_mem_usage(historical_transactions_sin)\n",
    "new_transactions_sin = reduce_mem_usage(new_transactions_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purchase_month列を追加\n",
    "\n",
    "historical_transactions_sin['purchase_month'] = historical_transactions_sin['purchase_date'].dt.to_period('M').dt.to_timestamp()\n",
    "new_transactions_sin['purchase_month'] = new_transactions_sin['purchase_date'].dt.to_period('M').dt.to_timestamp()\n",
    "historical_transactions_sin['purchase_year'] = historical_transactions_sin['purchase_date'].dt.year\n",
    "new_transactions_sin['purchase_year'] = new_transactions_sin['purchase_date'].dt.year\n",
    "historical_transactions_sin['epoch'] = pd.DatetimeIndex(historical_transactions_sin['purchase_date']).astype(np.int64) * 1e-9\n",
    "new_transactions_sin['epoch'] = pd.DatetimeIndex(new_transactions_sin['purchase_date']).astype(np.int64) * 1e-9\n",
    "\n",
    "\n",
    "all_transactions = pd.concat([historical_transactions_sin, new_transactions_sin], axis=0).reset_index(drop=True)\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions_sin[historical_transactions_sin['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions_sin[historical_transactions_sin['authorized_flag'] == 0]\n",
    "new_transactions = new_transactions_sin.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1689.24 Mb (9.5% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1597.89 Mb (11.3% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.int16)\n",
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\2557688541.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 156.02 Mb (8.5% reduction)\n",
      "Mem. usage decreased to 102.97 Mb (9.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "all_transactions = reduce_mem_usage(all_transactions)\n",
    "authorized_transactions = reduce_mem_usage(authorized_transactions)\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fumika.sambe.su\\AppData\\Local\\Temp\\ipykernel_5968\\112637800.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  authorized_transactions['purchase_amount'] = authorized_transactions['purchase_amount'].astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "authorized_transactions['purchase_amount'] = authorized_transactions['purchase_amount'].astype(np.float32)\n",
    "new_transactions['purchase_amount'] = new_transactions['purchase_amount'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_transactions_sin\n",
    "del historical_transactions_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value1(df, suf=None):\n",
    "    valuelist = ['day_of_year', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'purchase_year', 'epoch']\n",
    "    valuelistwc = ['card_id', 'day_of_year', 'day_of_year_sin', 'day_of_year_cos',\n",
    "            'day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'purchase_year', 'epoch']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "    for mode in ['max', 'min', 'old', 'new']:\n",
    "        if mode == 'max':\n",
    "            amt_idx = df.groupby('card_id')['purchase_amount'].idxmax()\n",
    "        elif mode == 'min':\n",
    "            amt_idx = df.groupby('card_id')['purchase_amount'].idxmin()\n",
    "        elif mode == 'old':\n",
    "            amt_idx = df.groupby('card_id')['purchase_date'].idxmin()\n",
    "        elif mode == 'new':\n",
    "            amt_idx = df.groupby('card_id')['purchase_date'].idxmax()\n",
    "        kari_add_df = pd.merge(kari_add_df, df.loc[amt_idx, valuelistwc], how='left', on='card_id', suffixes=['', ('_' + suf + mode)])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーごとの最高額、最低額、最初の決済、最後の決済の日時情報\n",
    "add_df = all_transactions.card_id.drop_duplicates()\n",
    "add_df = pd.merge(add_df,value1(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value1(new_transactions, 'new'), on='card_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value2(df, suf=None):\n",
    "    valuelist = ['day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'epoch']\n",
    "    valuelistwc = ['card_id','day_of_month', 'day_of_month_sin', 'day_of_month_cos',\n",
    "            'day_of_week', 'day_of_week_sin', 'day_of_week_cos',\n",
    "            'hour_of_day', 'hour_of_day_sin', 'hour_of_day_cos', 'epoch']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "\n",
    "    for mode in ['allmean', 'newmean', 'maxmean']:\n",
    "        if mode == 'allmean':\n",
    "            dfagg = df.groupby('card_id').mean()[valuelist]\n",
    "        elif mode == 'newmean':\n",
    "            a = df.groupby('card_id')['purchase_month'].max()\n",
    "            dfagg = df.merge(a, how='inner', on=['card_id', 'purchase_month']).groupby('card_id').mean()[valuelist]\n",
    "        elif mode == 'maxmean':\n",
    "            a = df.groupby(['card_id', 'purchase_month'])['purchase_amount'].sum().reset_index()\n",
    "            dfagg = df.merge(a.loc[a.groupby('card_id')['purchase_amount'].idxmax()][['card_id', 'purchase_month']], how='inner', on=['card_id', 'purchase_month']).groupby('card_id').mean()[valuelist]\n",
    "        # elif mode == 'allmode':\n",
    "        #     amt_idx = df.groupby('card_id')['purchase_date'].idxmax()\n",
    "        kari_add_df = pd.merge(kari_add_df, dfagg, how='left', on='card_id', suffixes=['', ('_' + suf + mode)])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーごとの全期間、最新月、決済金額合計が最大となる月それぞれの平均日時情報\n",
    "add_df = pd.merge(add_df,value2(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value2(new_transactions, 'new'), on='card_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value3(df, suf=None):\n",
    "    valuelist = ['day_of_week', 'purchase_year', 'purchase_month']\n",
    "    kari_add_df = all_transactions.card_id.drop_duplicates()\n",
    "    kari_add_df = pd.DataFrame(kari_add_df.reset_index(drop=True))\n",
    "    kari_add_df[valuelist] = 0\n",
    "    dfagg = df.groupby('card_id')[valuelist].apply(lambda x: x.mode()).reset_index().groupby('card_id')[valuelist].max()\n",
    "    kari_add_df = pd.merge(kari_add_df, dfagg, how='left', on='card_id', suffixes=['', ('_' + suf + 'allmode')])\n",
    "    return kari_add_df.drop(columns=valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.merge(add_df,value3(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(authorized_transactions, 'auth'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(historical_transactions, 'hist'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value3(new_transactions, 'new'), on='card_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['purchase_amount'] < row['Q1']:\n",
    "        return 'up25_mean'\n",
    "    elif row['purchase_amount'] > row['Q3']:\n",
    "        return '25-75_mean'\n",
    "    else:\n",
    "        return 'under25_mean'\n",
    "\n",
    "def value4(df, suf=None):\n",
    "\n",
    "    kari_add_df = df.groupby('card_id').purchase_date.count().rename('purchase_count')\n",
    "\n",
    "    percentiles = df.groupby('card_id')['purchase_amount'].quantile([0.25, 0.75]).unstack(level=1)\n",
    "    percentiles.columns = ['Q1', 'Q3']\n",
    "    dff = pd.merge(df, percentiles, on='card_id', how='left')\n",
    "    dff['amount_rank'] = dff.apply(categorize, axis=1)\n",
    "\n",
    "    kari_add_df = pd.merge(kari_add_df, dff.groupby(['card_id', 'amount_rank'])['purchase_amount'].mean().unstack(), on='card_id', how='left')\n",
    "    kari_add_df['diff_up25-2575'] = kari_add_df['up25_mean'] - kari_add_df['25-75_mean']\n",
    "    kari_add_df['diff_2575-under25'] = kari_add_df['25-75_mean'] - kari_add_df['under25_mean']\n",
    "    kari_add_df['diff_up25-under25'] = kari_add_df['up25_mean'] - kari_add_df['under25_mean']\n",
    "    kari_add_df['ratio_up25/2575'] = kari_add_df['up25_mean'] / kari_add_df['25-75_mean']\n",
    "    kari_add_df['ratio_under25/2575'] = kari_add_df['under25_mean'] / kari_add_df['25-75_mean']\n",
    "    return kari_add_df.add_suffix('_' + suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.merge(add_df,value4(all_transactions, 'all'), on='card_id', how='inner')\n",
    "add_df = pd.merge(add_df,value4(authorized_transactions, 'auth'), on='card_id', how='left')\n",
    "add_df = pd.merge(add_df,value4(historical_transactions, 'hist'), on='card_id', how='left')\n",
    "add_df = pd.merge(add_df,value4(new_transactions, 'new'), on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = read_data('../data/processed/processed20240625_train.csv')\n",
    "test = read_data('../data/processed/processed20240625_test.csv')\n",
    "\n",
    "\n",
    "train = pd.merge(train, add_df, on='card_id', how='left')\n",
    "test = pd.merge(test, add_df, on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240627_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240627_test.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
